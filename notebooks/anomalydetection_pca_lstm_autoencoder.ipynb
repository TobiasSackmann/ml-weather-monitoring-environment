{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.insert(1, '../library')\n",
    "import database_helper\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input, LSTM, RepeatVector, TimeDistributed, Dense\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = \"user\"\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = \"password\"\n",
    "mlflow.set_tracking_uri(uri=\"http://mlflow.local:80\")\n",
    "mlflow.set_experiment(\"DWD Autoencoder Anomaly Detection\")\n",
    "mlflow.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('selected_columns.pkl', 'rb') as f:\n",
    "    selected_columns = pickle.load(f)\n",
    "dataframe = database_helper.query_data(field_list=selected_columns)\n",
    "dataframe['_time'] = pd.to_datetime(dataframe['_time'])\n",
    "dataframe.set_index('_time', inplace=True)\n",
    "dataframe = dataframe.select_dtypes(include='float64')\n",
    "dataframe.interpolate(inplace=True)\n",
    "display(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(dataframe)\n",
    "display(data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data_scaled, test_size=0.2) #, random_state=42\n",
    "\n",
    "n_samples = 1000\n",
    "time_steps = 1\n",
    "n_features = train_data.shape[1]  # Assuming univariate time series\n",
    "\n",
    "# Define the LSTM autoencoder model\n",
    "input_dim = train_data.shape[1:]  # (time_steps, n_features)\n",
    "latent_dim = 32  # Compressed representation dimension\n",
    "\n",
    "input_layer = Input(shape=input_dim)\n",
    "encoder = LSTM(128, activation=\"relu\", return_sequences=True)(input_layer)\n",
    "encoder = LSTM(64, activation=\"relu\", return_sequences=False)(encoder)\n",
    "encoder_output = RepeatVector(time_steps)(encoder)\n",
    "\n",
    "decoder = LSTM(64, activation=\"relu\", return_sequences=True)(encoder_output)\n",
    "decoder = LSTM(128, activation=\"relu\", return_sequences=True)(decoder)\n",
    "decoder_output = TimeDistributed(Dense(n_features))(decoder)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "display(autoencoder.summary())\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "autoencoder.compile(optimizer=optimizer, loss='mse', metrics=['mse', 'accuracy'])\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(train_data, train_data, \n",
    "                epochs=150, \n",
    "                batch_size=32, \n",
    "                validation_split=0.2, \n",
    "                verbose=1,\n",
    "                callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the autoencoder to reconstruct the test data\n",
    "reconstructed_data = autoencoder.predict(test_data)\n",
    "\n",
    "# Calculate reconstruction error\n",
    "reconstruction_error = np.mean(np.square(test_data - reconstructed_data), axis=1)\n",
    "\n",
    "# Define a threshold for anomaly detection (this is a simple way, more advanced methods can be used)\n",
    "threshold = np.percentile(reconstruction_error, 95)\n",
    "\n",
    "# Identify anomalies\n",
    "anomalies = reconstruction_error > threshold\n",
    "\n",
    "# Print results\n",
    "print(\"Number of anomalies detected:\", np.sum(anomalies))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
