{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "from influxdb_client import InfluxDBClient, Point\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "sys.path.insert(1, \"../library\")  # noqa: E402\n",
    "import database_helper  # noqa: E402"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"selected_columns.pkl\", \"rb\") as f:\n",
    "    selected_columns = pickle.load(f)\n",
    "    print(selected_columns)\n",
    "\n",
    "strings_to_exclude = [\"icon\", \"moon\", \"warning\"]\n",
    "selected_columns = [\n",
    "    item\n",
    "    for item in selected_columns\n",
    "    if not any(substring in item for substring in strings_to_exclude)\n",
    "]\n",
    "\n",
    "strings_to_include = [\"days_0\", \"10838\"]\n",
    "selected_columns = [\n",
    "    item\n",
    "    for item in selected_columns\n",
    "    if all(substring in item for substring in strings_to_include)\n",
    "]\n",
    "\n",
    "print(str(len(selected_columns)) + \" Features selected\")\n",
    "df = database_helper.query_data(\n",
    "    field_list=selected_columns, start_time=\"2025-01-01T12:00:00Z\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(\"_time\", inplace=True)\n",
    "df = df.select_dtypes(include=\"float64\")\n",
    "df.interpolate(inplace=True)\n",
    "df = df.resample(\"h\").mean()\n",
    "df.reset_index(inplace=True)\n",
    "date_time = pd.to_datetime(df.pop(\"_time\"), format=\"%d.%m.%Y %H:%M:%S\")\n",
    "\n",
    "display(df.head())\n",
    "display(date_time[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_s = date_time.map(pd.Timestamp.timestamp)\n",
    "day = 24 * 60 * 60\n",
    "year = (365.2425) * day\n",
    "\n",
    "df[\"Day sin\"] = np.sin(timestamp_s * (2 * np.pi / day))\n",
    "df[\"Day cos\"] = np.cos(timestamp_s * (2 * np.pi / day))\n",
    "df[\"Year sin\"] = np.sin(timestamp_s * (2 * np.pi / year))\n",
    "df[\"Year cos\"] = np.cos(timestamp_s * (2 * np.pi / year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (df - df.mean()) / df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = df.shape[1]\n",
    "time_range = 24\n",
    "df = df[:time_range]\n",
    "print(df.shape, num_features, time_range)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "display(df.head())\n",
    "data = json.dumps(\n",
    "    {\"signature_name\": \"serving_default\", \"instances\": np.array(df).tolist()}\n",
    ")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"content-type\": \"application/json\"}\n",
    "json_response = requests.post(\n",
    "    \"http://localhost:8501/v1/models/waether-timeseries-forecasts:predict\",\n",
    "    data=data,\n",
    "    headers=headers,\n",
    ")\n",
    "response = json.loads(json_response.text)\n",
    "predictions = response[\"predictions\"]\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_timestamps(n):\n",
    "    # Aktuelle Zeit in Berliner Zeitzone (CET/CEST)\n",
    "    now = datetime.now(pytz.timezone(\"Europe/Berlin\"))\n",
    "    print(now)\n",
    "    timestamps = []\n",
    "    # Erstelle 'n' Timestamps, die jeweils 1 Stunde auseinanderliegen\n",
    "    for i in range(n):\n",
    "        timestamp = now + timedelta(hours=i + 1)\n",
    "        timestamps.append(timestamp.strftime(\"%Y-%m-%d %H:%M:%S%z\"))\n",
    "    return timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFLUXDB_URL = \"http://tig.influxdb.local\"\n",
    "INFLUXDB_TOKEN = os.getenv(\"INFLUXDB2_TOKEN\")\n",
    "INFLUXDB_ORG = os.getenv(\"INFLUXDB2_ORGANIZATION\")\n",
    "INPUT_BUCKET = os.getenv(\"INFLUXDB2_BUCKET\")\n",
    "OUTPUT_BUCKET = os.getenv(\"INFLUXDB2_ML_BUCKET\")\n",
    "\n",
    "client = InfluxDBClient(url=INFLUXDB_URL, token=INFLUXDB_TOKEN, org=INFLUXDB_ORG)\n",
    "write_api = client.write_api(write_options=SYNCHRONOUS)\n",
    "timestamps = generate_timestamps(len(predictions))\n",
    "\n",
    "if predictions:\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        point = Point(\"inference_result\").time(timestamps[i])\n",
    "        for y, field in enumerate(prediction):\n",
    "            point.field(df.columns[y], float(prediction[y]))\n",
    "        write_api.write(bucket=OUTPUT_BUCKET, org=INFLUXDB_ORG, record=point)\n",
    "    print(\"Predictions written to InfluxDB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
